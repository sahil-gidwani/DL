import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt

dataset = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = dataset.load_data()

# Normalize the images
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture
model = keras.Sequential([
    # Flatten layer to convert 2D input into 1D
    keras.layers.Flatten(input_shape=(28, 28)),
    # Dense layer with 128 neurons and ReLU activation function
    keras.layers.Dense(128, activation='relu'),
    # Output layer with 10 neurons and softmax activation function for classification
    keras.layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(train_images, train_labels, epochs=10)

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels)
print('Test accuracy:', test_acc)

# Make predictions and show example images with predicted labels
num_rows = 5
num_cols = 5
num_images = num_rows * num_cols

plt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))
for i in range(num_images):
    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)
    plt.imshow(test_images[i], cmap='gray')
    plt.axis('off')

    # Make predictions for the current image
    predictions = model.predict(np.expand_dims(test_images[i], axis=0))
    predicted_label = np.argmax(predictions)

    plt.subplot(num_rows, 2 * num_cols, 2 * i + 2)
    plt.bar(range(10), predictions[0])
    plt.xticks(range(10))
    plt.ylim([0, 1])
    plt.title(f"Predicted label: {predicted_label}")

plt.tight_layout()
plt.show()

"""
### Introduction to CNNs:

Convolutional Neural Networks (CNNs) are a class of deep neural networks primarily designed to process and analyze structured grid-like data, such as images. They are widely used in various computer vision tasks, including image classification, object detection, and image segmentation.

### Key Components of CNNs:

1. **Convolutional Layers**: The core building blocks of CNNs are convolutional layers. These layers consist of filters (also called kernels) that slide over the input image to perform convolution operations. Each filter captures specific patterns or features from the input, such as edges, textures, or shapes. During training, the network learns the optimal filter weights to extract relevant features automatically.

2. **Activation Function**: Typically, each convolutional layer is followed by an activation function, such as ReLU (Rectified Linear Unit), to introduce non-linearity into the network and enable it to learn complex relationships in the data.

3. **Pooling Layers**: Pooling layers are used to downsample the feature maps generated by convolutional layers. Common pooling operations include max pooling and average pooling, which reduce the spatial dimensions of the feature maps while retaining the most important information. Pooling helps to make the network more robust to variations in input and reduces the computational complexity of subsequent layers.

4. **Fully Connected Layers**: After several convolutional and pooling layers, CNNs often include one or more fully connected layers at the end of the network. These layers are similar to those in traditional feedforward neural networks and serve to classify the extracted features into different categories or classes.

5. **Softmax Layer**: In classification tasks, the output layer of the CNN typically consists of a softmax activation function, which converts the raw scores generated by the previous layer into probabilities. Each probability represents the likelihood of the input belonging to a particular class.

### Training Process:

1. **Initialization**: The parameters (weights and biases) of the CNN are initialized randomly or using pre-trained weights (transfer learning).

2. **Forward Propagation**: During the forward pass, input images are fed into the network, and the activations are computed layer by layer. Convolution, activation, and pooling operations transform the input into a hierarchical representation of features.

3. **Loss Calculation**: The output of the network is compared to the ground truth labels using a loss function, such as cross-entropy loss for classification tasks or mean squared error for regression tasks. The loss quantifies the difference between the predicted and actual outputs.

4. **Backpropagation**: Backpropagation is used to compute the gradients of the loss function with respect to the network parameters. These gradients are then used to update the weights and biases of the network using optimization algorithms such as stochastic gradient descent (SGD), Adam, or RMSprop.

5. **Iteration**: The process of forward propagation, loss calculation, and backpropagation is repeated iteratively over the training dataset (epochs) until the model converges to a satisfactory solution or reaches a predefined stopping criterion.

### Advantages of CNNs:

1. **Feature Learning**: CNNs automatically learn hierarchical representations of features directly from raw input data, eliminating the need for handcrafted feature extraction.

2. **Translation Invariance**: Convolutional operations enable CNNs to capture spatial hierarchies of features, making them invariant to translation, rotation, and scale variations in input images.

3. **Parameter Sharing**: By sharing weights across different regions of the input, CNNs are more parameter efficient and can generalize better to unseen data.

4. **State-of-the-Art Performance**: CNNs have achieved remarkable performance in various computer vision tasks, often outperforming traditional machine learning approaches and human benchmarks.

In summary, Convolutional Neural Networks are a powerful class of deep learning models tailored for processing and analyzing structured grid-like data, particularly images. Their ability to automatically learn hierarchical representations of features has revolutionized the field of computer vision and enabled significant advancements in artificial intelligence.

Certainly! Let's break down the Convolutional Neural Network (CNN) process and architecture in detail.

### 1. Convolutional Layer:

- **Convolution Operation**: In the convolutional layer, a set of learnable filters (also known as kernels) slides over the input image. Each filter performs element-wise multiplication with a small region of the input image (receptive field) and then sums the results to produce a single value in the output feature map. This operation captures local patterns or features present in the input image.

- **Padding**: Padding is often added to the input image to preserve spatial dimensions in the output feature maps. Zero-padding is commonly used, where zeros are added around the input image borders.

- **Stride**: The stride determines the step size at which the filter moves across the input image. A larger stride results in smaller output feature maps.

### 2. Activation Function:

- After the convolution operation, an activation function such as ReLU (Rectified Linear Unit) is applied element-wise to the output feature maps. ReLU introduces non-linearity into the network, enabling it to learn complex patterns and relationships in the data.

### 3. Pooling Layer:

- **Pooling Operation**: Pooling layers reduce the spatial dimensions of the feature maps while retaining the most important information. Max pooling and average pooling are commonly used pooling operations. Max pooling selects the maximum value within each pooling window, while average pooling computes the average value.

- **Downsampling**: Pooling helps to downsample the feature maps, making the network more computationally efficient and robust to variations in input.

### 4. Fully Connected Layers:

- After several convolutional and pooling layers, the high-level features are flattened into a vector and passed through one or more fully connected layers. These layers perform classification or regression tasks by learning the relationships between the extracted features and the target labels.

### 5. Output Layer:

- The output layer of the CNN typically consists of one or more neurons, depending on the number of classes in the classification task. For multi-class classification tasks, a softmax activation function is often applied to produce class probabilities, while for binary classification tasks, a sigmoid activation function is used.

### CNN Architecture:

- **Input Layer**: The input layer receives the raw input data, such as images, with each pixel representing a feature.

- **Convolutional Layers**: Multiple convolutional layers with learnable filters extract hierarchical representations of features from the input data.

- **Activation Function**: ReLU or other activation functions introduce non-linearity into the network, enabling it to learn complex patterns.

- **Pooling Layers**: Pooling layers downsample the feature maps, reducing spatial dimensions and computational complexity.

- **Fully Connected Layers**: Fully connected layers at the end of the network perform classification or regression tasks based on the learned features.

- **Output Layer**: The output layer produces the final predictions or class probabilities.

### Training Process:

- **Initialization**: The parameters of the CNN, including filter weights and biases, are initialized randomly or using pre-trained weights.

- **Forward Propagation**: During the forward pass, input data is fed into the network, and activations are computed layer by layer through convolution, activation, and pooling operations.

- **Loss Calculation**: The output of the network is compared to the ground truth labels using a loss function, such as cross-entropy loss for classification tasks.

- **Backpropagation**: Gradients of the loss function with respect to the network parameters are computed using backpropagation. These gradients are then used to update the parameters using optimization algorithms such as stochastic gradient descent (SGD) or Adam.

- **Iteration**: The process of forward propagation, loss calculation, and backpropagation is repeated iteratively over the training dataset (epochs) until the model converges to a satisfactory solution.

### Summary:

Convolutional Neural Networks are a powerful class of deep learning models tailored for processing and analyzing structured grid-like data, particularly images. Their hierarchical architecture, which includes convolutional layers, activation functions, pooling layers, fully connected layers, and output layers, enables them to automatically learn features and patterns directly from raw input data, leading to state-of-the-art performance in various computer vision tasks.
"""
